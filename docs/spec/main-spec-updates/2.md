# Spec Update 2 - Genestack Uploader Version 2

Now the Genestack Uploader has been used in production, some issues have arisen that should be fixed, which will be set out in this spec. As some of these will be breaking changes, we'll update the version numbering to 2.X.

## Logging

In the Docker environment, Flask buffers `stdout` and `stderr`, meaning we don't get logs unless it is flushed. Although there is an environment variable that can be set to stop this buffering, instead we will replace all print statements throughout both this app and the `uploadtogenestack` package with methods from the Python `logging` module. 

Each logger will be named either after the class it is contained in, or another appropriate name for the function the code is carrying out. As Docker logs can capture the timestamp, we can use the default logging format from this module, containing the logger name, log level and log message.

In the `uploadtogenestack` package, coloured output is used. These will be converted as follows:

| Colour | Log Level |
|--------|-----------|
| Green  | INFO      |
| Yellow | WARNING   |
| Red    | ERROR     |

Throughout the web app, exceptions (even if caught) should be passed to the `exception` method of the logger where appropriate.

In production, logging should be set at the `INFO` level, however this should be able to be changed through an environment variable.

## Sanitising Inputs

Text inputs should be stripped, removing whitespace from the start and end of inputs. For example, in the column renaming inputs, accidental whitespace can cause the column not to be found.

Also, for S3 paths, the `s3://bucketname/` should be stripped if provided, as it will already be accounted for.

## S3 File Error Messages

It turns out that if a file in a S3 bucket can't be found, instead of giving some form of `FileNotFoundError` it gives a `S3 bucket permission denied`. This is very unhelpful (as well as straight up wrong), as it doesn't indicate that maybe the user has typed the file path wrong.

We need to make sure all errors returned to the user actually are the encountered errors - there is a chance it is confused by the context manager surrounding the request.

## Column Renaming Issues

1. The logic in the `uploadtogenestack` package for renaming sample file columns isn't correct. It assumes the columns provided in the rename file will be in the same order as the columns in the original file by just writing the row out as is. This shouldn't be the case - it shouldn't matter which order the user puts the columns to rename in.

2. The interface on the web form for changing/adding columns is simply based on the filetype that the `uploadtogenestack` package expects. Although it isn't the most complicated thing in the world to work out, it's more complicated that neccesary. It would be good to split this into two form parts:
    - Renaming Columns with `Old Header` and `New Header`
    - Adding Columns with `Column Header` and `Value`

    These changes will be reflected in the API docs.

3. As the columns `Sample Source ID` and `Sample Source` are required, it would be a good idea to describe this on the web app.

## Column Renaming Error Messages

When there is an issue renaming the columns, the `uploadtogenestack` package returns a really unhelpful error message, which certainly needs changing. It may also be an idea to catch this error and return something that isn't an `Internal Server Error` to the user, such as a `400 Bad Request`.

## Sample Templates

Although the study metadata and signal data all allow the user to select which template they want to use, the sample data doesn't - so it uses the default one. This should be changed, so you can select a template for the sample data. It would then also be good to check whether the signal template selection is for just the metadata, or both the metadata and actual data.

These changes will be reflected in the API docs.

## Deleting Temporary Files

As the web server creates various temporary files during the process, such as downloading the samples from S3, they should all be cleared up afterwards so we don't just keep using unnecesary space.

## Jobs Queue

The entire upload process is done during the HTTP request, so a respone isn't sent until the upload is done. This can take many minutes, just leaving the request open. The timeout on our nginx has already had to be dramatically increased to help this, and sometimes due to the time waiting for the response, the response doesn't actually get back to the user for some reason, so they're just left waiting.

This can be resolved by the request submitting an upload "job", and immediately return a job UUID to the user. The web app can then poll a new endpoint `/api/jobs/{uuid}` to get the status of the job. It should be a configurable option for how long after the job has completed that its status can be retrieved.

This will also allow the user to close their web browser whilst the upload is in process. When they return to the web app, it may be good to have a list of jobs and their progress, which can be returned over a new endpoint `/api/jobs`.

The JSON response for a job will be:
```json
{
    "status": "RUNNING|COMPLETED|FAILED",
    "startTime": "2021-01-21 10:00:00",
    "endTime": "2021-01-21 10:10:00",
    "output": {
        "key": "value"
    }
}
```